---
title: "README"
author: "Andrew MacDonald"
date: "May 25, 2015"
output: md_document
---

[![Travis-CI Build Status](https://travis-ci.org/SrivastavaLab/bwgtools.png?branch=master)](https://travis-ci.org/SrivastavaLab/bwgtools)

# Introduction
This is an R package for the bromeliad working group rainfall experiment. Our intention is to create a set of tools that facilitate all steps of the process:

* loading data into R
* combining data from different replicates
* performing calculations

At present the package allows each group of authors to obtain the datasets they will need to **begin** their analysis.

Please [open an issue](https://github.com/SrivastavaLab/bwgtools/issues) if there is a feature you would like to see, or if you discover an error or bug!

# Installation

`bwgtools` can be installed directly from Github using devtools:

```r
install.packages("devtools") # if you don't have devtools
library(devtools)
install_github("SrivastavaLab/bwgtools", dependencies = TRUE)
```

# Accessing Dropbox

`bwgtools` uses [rdrop2](https://github.com/karthik/rdrop2) to access your Dropbox account, then uses [readxl](https://github.com/hadley/readxl) to download the data and read it directly into R. When you first run `library(bwgtools)` you will see the following message:

```{r}
library(bwgtools)
```

## Important Note: Protect your account!

**In Dropbox:** by default, `drop_auth()` saves your Dropbox login to a file called `.httr-oauth`. Of course, we don't want this shared with everyone in our Dropbox folder, as they would then be able to access your personal Dropbox account! Therefore, we set `cache=FALSE`. This will require us to re-authenticate every time we want to download fresh data. This should be a quick and painless process, especially if you are already logged in on your computer. However, bwgtools should work from any computer connected to the internet, provided that you have your Dropbox username and password.

**Working outside of Dropbox:** running `drop_acc()` or `drop_auth()` will create a file called `.httr-oauth` in your directory, which will contain your login credentials for Dropbox. **Remember to add this file to your .gitignore if you are using git**. For more information, see `?rdrop2::drop_auth`. 

# Reading a single sheet

Once you have authenticated with Dropbox, you can read data directly into R. To obtain a single tab (for example, the "leaf.waterdepths" tab) for a single site (for example, Macae), use the function `read_sheet_site`:

```{r}
macae <- read_site_sheet("Macae", "leaf.waterdepths")

knitr::kable(head(macae))
```

## Working offline
The first argument to this function can either be the name of a site (`"Macae"`, in the example above), **or** a path to the location of the file on your hard drive. For example, on my (Andrew's) computer, the path to Dropbox is:

```
../../../Dropbox
```

So I could read in my local copy of the data like this:

```{r}
macae <- read_site_sheet("../../../Dropbox/BWG Drought Experiment/raw data/Drought_data_Macae.xlsx", "leaf.waterdepths")
```

This is an example of a _relative path_; the symbol `..` means "one directory above my current location". This is the relative path _from_ the directory where I am developing `bwgtools` _to_ the directory where the Macae data is stored, on my machine. There is more information about relative paths [here](http://swcarpentry.github.io/shell-novice/01-filedir.html). 

To save typing, I've made a convenience function that fills in the relative path for you. It requires the name of the sheet you want, and the path from your current working directory to the full Dropbox folder: 

```{r}
macae <- read_site_sheet(offline("Macae", default.path = "../../../Dropbox/"), "leaf.waterdepths")

## or, equivalently:
library(magrittr)

macae <- "Macae" %>% 
  offline(default.path = "../../../Dropbox/") %>%  ## use your own path
  read_site_sheet(sheetname = "leaf.waterdepths")

```

**PLEASE NOTE**: the major _disadvantage_ of this approach is that your local version of the data may be behind the official version on the Dropbox website. To be safe, use the online version whenever you can.

# Reading multiple sheets

For all our analyses, we will need to collect data from all sites. ; we can also load and combine the same tab across all sites, with a single function: `combine_tab()`. This function has two arguments: the first is a vector of all the site names (as spelt in the file names in the `raw data/` folder). The second is the name of the sheet to read (as above). For example, to obtain the "site.info" tab for all sites, use the following command:

```{r, warning=FALSE, message=FALSE, results='asis'}
library(dplyr)
library(knitr)
c("Argentina", "French_Guiana", "Colombia",
  "Macae", "PuertoRico","CostaRica") %>%
  combine_tab(sheetname = "site.info") %>% 
  head %>% 
  kable
```

`combine_tab()` does a little bit more than simply combine the output of `read_site_sheet()`. It also checks the names of the datasets before combining, creates unique bromeliad id numbers, and reshapes the invertebrate data from "wide" to "long" format. Here is a quick explanation of each of these modifications in turn:

## bromeliad ids

Many sites have simply numbered their bromeliads, meaning that there are several bromeliads labelled "1", each in a different site. This is not an error on the part of researchers, however it is a potential danger when combining datasets. To make the bromeliad identification numbers unambiguous, I have combined the site name and the bromeliad name into a new variable, "`site_brom.id`":

```{r}
phys_data <- c("Argentina", "French_Guiana", "Colombia",
  "Macae", "PuertoRico","CostaRica") %>%
  combine_tab(sheetname = "bromeliad.physical")

kable(phys_data[1:6, 1:3])
```




### Licence
We release the code in this repository under the MIT software license. see text of license [here](LICENSE)
